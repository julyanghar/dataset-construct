import torch
from transformers import AutoImageProcessor, AutoModel
from transformers.image_utils import load_image
import argparse
from datasets import Dataset
from datasets import load_dataset
from PIL import Image
import os
import torch.nn.functional as F
from tqdm import tqdm
import json

def parse_eval_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("--config", default="", help="Path to a yaml file specifying all arguments, will ignore cli arguments if specified")
    parser.add_argument("--pretrained_model_name", default="hf", help="Name of model e.g. `hf`")
    parser.add_argument("--output_dir",
        default=None,
        help="output folder"
    )
    parser.add_argument("--image_folder",
        default=None,
        help="image folder"
    )
    parser.add_argument("--data_path",
        default=None,
        help="data folder"
    )
    parser.add_argument("--similarity_type",
        default="pooler_output",
        help="The way calculate cosine similarity"
    )
    args = parser.parse_args()
    return args



def convert_record(record, idx):
    # return {
    #     "idx": idx,
    #     "image": record.get("image"),
    #     "retrieved_image": None,
    #     "masked_response": None,
    #     "chosen": [
    #         {
    #             "content": record.get("prompt", ""),
    #             "role": "user"
    #         },
    #         {
    #             "content": record.get("chosen", ""),
    #             "role": "assistant"
    #         }
    #     ],
    #     "rejected": [
    #         {
    #             "content": record.get("prompt", ""),
    #             "role": "user"
    #         },
    #         {
    #             "content": record.get("rejected", ""),
    #             "role": "assistant"
    #         }
    #     ],
    #     "img_similarity": None,
    #     "text_similarity": None
    # }
    converted = {
        "idx": idx,  # å¯ä»¥æ ¹æ®éœ€è¦ç”Ÿæˆ
        "image": record["img_path"],
        "retrieved_image": None,
        "masked_response": None,
        "chosen": [
            {"content": record["prompt"], "role": "user"},
            {"content": record["chosen"], "role": "assistant"}
        ],
        "rejected": [
            {"content": record["prompt"], "role": "user"},
            {"content": record["rejected"], "role": "assistant"}
        ],
        "img_similarity": None,
        "text_similarity": None
    }
    return converted



def convert_records(input_path, output_path):

    # è¯»å–æ•´ä¸ª JSON æ–‡ä»¶
    with open(input_path, "r", encoding="utf-8") as fin:
        data = json.load(fin)   # å‡è®¾ data æ˜¯ list

    # valid_prefixes = ('mcq', 'long', 'short')
    # filtered_data = [
    #     item for item in data
    #     if item.get("image") and item["image"].startswith(valid_prefixes)
    # ]
    # è½¬æ¢æ¯ä¸€æ¡æ ·æœ¬
    
    converted = []
    for idx, record in tqdm(enumerate(data), total=len(data), desc="Converting", unit="item"):
        converted.append(convert_record(record, idx))

    # å†™å‡ºåˆ° JSON æ–‡ä»¶
    with open(output_path, "w", encoding="utf-8") as fout:
        json.dump(converted, fout, ensure_ascii=False, indent=4)

    print(f"âœ… å·²å®Œæˆè½¬æ¢ï¼Œè¾“å‡ºä¿å­˜åˆ°ï¼š{output_path}")





if __name__ == "__main__":
    args = parse_eval_args()
    input_path = "./preference_data/vlfeedback_llava_10k.json"   # ğŸ‘ˆ ä½ çš„åŸå§‹æ–‡ä»¶
    output_path = "./preference_data/converted_vlfeedback_llava_10k.json" # ğŸ‘ˆ è½¬æ¢åçš„ç›®æ ‡æ–‡ä»¶
    convert_records(input_path, output_path)
    